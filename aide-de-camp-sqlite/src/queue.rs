use crate::job_handle::SqliteJobHandle;
use crate::types::JobRow;
use aide_de_camp::core::job_processor::JobProcessor;
use aide_de_camp::core::queue::{Queue, QueueError};
use aide_de_camp::core::{new_xid, DateTime, Xid};
use anyhow::Context;
use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use sqlx::{FromRow, QueryBuilder, SqlitePool};
use tracing::instrument;

/// An implementation of the Queue backed by SQlite
#[derive(Clone)]
pub struct SqliteQueue {
    pub(crate) pool: SqlitePool,
}

impl SqliteQueue {
    pub fn with_pool(pool: SqlitePool) -> Self {
        Self { pool }
    }
}

#[async_trait]
impl Queue for SqliteQueue {
    type JobHandle = SqliteJobHandle;

    #[instrument(skip_all, err, ret, fields(job_type = J::name(), payload_size))]
    async fn schedule_at<J>(
        &self,
        payload: J::Payload,
        scheduled_at: DateTime,
        priority: i8,
    ) -> Result<Xid, QueueError>
    where
        J: JobProcessor + 'static,
        J::Payload: Serialize,
    {
        let payload = serde_json::to_vec(&payload).map_err(QueueError::SerializeError)?;
        let jid = new_xid();
        let jid_string = jid.to_string();
        let job_type = J::name();

        tracing::Span::current().record("payload_size", payload.len());

        sqlx::query(
            "INSERT INTO adc_queue (jid,job_type,payload,scheduled_at,priority) VALUES (?1,?2,?3,?4,?5)"
        )
        .bind(jid_string)
        .bind(job_type)
        .bind(payload)
        .bind(scheduled_at)
        .bind(priority)
        .execute(&self.pool)
        .await
        .context("Failed to add job to the queue")?;
        Ok(jid)
    }

    #[instrument(skip_all, err, ret, fields(job_type))]
    async fn schedule_raw(
        &self,
        job_type: &str,
        payload: serde_json::Value,
        scheduled_at: DateTime,
        priority: i8,
    ) -> Result<Xid, QueueError> {
        let jid = new_xid();
        let jid_string = jid.to_string();

        // Serialize JSON to bytes for BLOB storage
        let payload_bytes = serde_json::to_vec(&payload).map_err(QueueError::SerializeError)?;

        tracing::Span::current().record("job_type", job_type);

        sqlx::query(
            "INSERT INTO adc_queue (jid,job_type,payload,scheduled_at,priority) VALUES (?1,?2,?3,?4,?5)"
        )
        .bind(jid_string)
        .bind(job_type)
        .bind(payload_bytes)
        .bind(scheduled_at)
        .bind(priority)
        .execute(&self.pool)
        .await
        .context("Failed to add job to the queue")?;
        Ok(jid)
    }

    #[instrument(skip_all, err)]
    async fn poll_next_with_instant(
        &self,
        job_types: &[&str],
        now: DateTime,
    ) -> Result<Option<SqliteJobHandle>, QueueError> {
        let mut builder =
            QueryBuilder::new("UPDATE adc_queue SET started_at=(strftime('%s', 'now')) ");
        let query = {
            builder.push(
                "WHERE jid IN (SELECT jid FROM adc_queue WHERE started_at IS NULL AND queue='default' AND scheduled_at <="
            );
            builder.push_bind(now);
            builder.push(" AND job_type IN (");
            {
                let mut separated = builder.separated(",");
                for job_type in job_types {
                    separated.push_bind(job_type);
                }
            }
            builder.push(") ORDER BY priority DESC LIMIT 1) RETURNING *");
            builder.build().bind(now)
        };
        let row = query
            .try_map(|row| JobRow::from_row(&row))
            .fetch_optional(&self.pool)
            .await
            .context("Failed to check out a job from the queue")?;

        if let Some(row) = row {
            Ok(Some(SqliteJobHandle::new(row, self.pool.clone())))
        } else {
            Ok(None)
        }
    }

    #[instrument(skip_all, err)]
    async fn cancel_job(&self, job_id: Xid) -> Result<(), QueueError> {
        let jid = job_id.to_string();
        let result = sqlx::query("DELETE FROM adc_queue WHERE started_at IS NULL and jid = ?")
            .bind(jid)
            .execute(&self.pool)
            .await
            .context("Failed to remove job from the queue")?;
        if result.rows_affected() == 0 {
            Err(QueueError::JobNotFound(job_id))
        } else {
            Ok(())
        }
    }

    #[allow(clippy::or_fun_call)]
    #[instrument(skip_all, err)]
    async fn unschedule_job<J>(&self, job_id: Xid) -> Result<J::Payload, QueueError>
    where
        J: JobProcessor + 'static,
        J::Payload: for<'de> Deserialize<'de>,
    {
        let jid = job_id.to_string();
        let job_type = J::name();
        let payload = sqlx::query_scalar::<_, Vec<u8>>(
            "DELETE FROM adc_queue WHERE started_at IS NULL and jid = ? AND job_type = ? RETURNING payload"
        )
        .bind(jid)
        .bind(job_type)
        .fetch_optional(&self.pool)
        .await
        .context("Failed to remove job from the queue")?
        .ok_or(QueueError::JobNotFound(job_id))?;
        let decoded = serde_json::from_slice(&payload).map_err(QueueError::DeserializeError)?;
        Ok(decoded)
    }
}
